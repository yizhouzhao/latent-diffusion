{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "021c3028-e56b-42aa-9e21-577b735b1280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.txt2img import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "312ad8e3-579e-4f43-8dc2-f77e37a74bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--prompt\",\n",
    "    type=str,\n",
    "    nargs=\"?\",\n",
    "    default=\"a painting of a virus monster playing guitar\",\n",
    "    help=\"the prompt to render\"\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--outdir\",\n",
    "    type=str,\n",
    "    nargs=\"?\",\n",
    "    help=\"dir to write results to\",\n",
    "    default=\"outputs/txt2img-samples\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--ddim_steps\",\n",
    "    type=int,\n",
    "    default=200,\n",
    "    help=\"number of ddim sampling steps\",\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--plms\",\n",
    "    action='store_true',\n",
    "    help=\"use plms sampling\",\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--ddim_eta\",\n",
    "    type=float,\n",
    "    default=0.0,\n",
    "    help=\"ddim eta (eta=0.0 corresponds to deterministic sampling\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n_iter\",\n",
    "    type=int,\n",
    "    default=1,\n",
    "    help=\"sample this often\",\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--H\",\n",
    "    type=int,\n",
    "    default=256,\n",
    "    help=\"image height, in pixel space\",\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--W\",\n",
    "    type=int,\n",
    "    default=256,\n",
    "    help=\"image width, in pixel space\",\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--n_samples\",\n",
    "    type=int,\n",
    "    default=4,\n",
    "    help=\"how many samples to produce for the given prompt\",\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--scale\",\n",
    "    type=float,\n",
    "    default=5.0,\n",
    "    help=\"unconditional guidance scale: eps = eps(x, empty) + scale * (eps(x, cond) - eps(x, empty))\",\n",
    ")\n",
    "\n",
    "opt = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "666eae5d-6506-4216-8045-69caee5a2408",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.prompt = \"who is calling me?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e6dd620-4ddc-4b0f-9d61-e985e5ab2136",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.ddim_eta = 1.0\n",
    "opt.n_samples = 1\n",
    "opt.n_iter = 1\n",
    "opt.H = 384\n",
    "opt.W = 1024\n",
    "opt.scale = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cf7b0d1-db7f-41e4-ad56-09f0f312b63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from models/ldm/text2img-large/model.ckpt\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "DiffusionWrapper has 872.30 M params.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n"
     ]
    }
   ],
   "source": [
    "config = OmegaConf.load(\"configs/latent-diffusion/txt2img-1p4B-eval.yaml\")  # TODO: Optionally download from same location as ckpt and chnage this logic\n",
    "model = load_model_from_config(config, \"models/ldm/text2img-large/model.ckpt\")  # TODO: check path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f4d8640-38be-4bdc-be79-3d2e988c92e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.plms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be9af22c-5f41-4c32-9d4d-0b3d91fd3e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt.plms:\n",
    "    sampler = PLMSSampler(model)\n",
    "else:\n",
    "    sampler = DDIMSampler(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "856f7533-1657-4b08-abf2-47e295cb8bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(opt.outdir, exist_ok=True)\n",
    "outpath = opt.outdir\n",
    "\n",
    "prompt = opt.prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab4c561e-03fb-43a4-bb2a-c2127701d3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_path = os.path.join(outpath, \"samples\")\n",
    "os.makedirs(sample_path, exist_ok=True)\n",
    "base_count = len(os.listdir(sample_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae070e0c-3aba-465f-8375-e53f95ad8af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples=list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "365f2ac5-412c-45af-aab5-785548909eff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDiffusion(\n",
       "  (model): DiffusionWrapper(\n",
       "    (diffusion_model): UNetModel(\n",
       "      (time_embed): Sequential(\n",
       "        (0): Linear(in_features=320, out_features=1280, bias=True)\n",
       "        (1): SiLU()\n",
       "        (2): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (input_blocks): ModuleList(\n",
       "        (0): TimestepEmbedSequential(\n",
       "          (0): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (1): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (1): SpatialTransformer(\n",
       "            (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "            (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): CrossAttention(\n",
       "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): CrossAttention(\n",
       "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (1): SpatialTransformer(\n",
       "            (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "            (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): CrossAttention(\n",
       "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): CrossAttention(\n",
       "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (3): TimestepEmbedSequential(\n",
       "          (0): Downsample(\n",
       "            (op): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (4): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatialTransformer(\n",
       "            (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): CrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): CrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (5): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (1): SpatialTransformer(\n",
       "            (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): CrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): CrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (6): TimestepEmbedSequential(\n",
       "          (0): Downsample(\n",
       "            (op): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (7): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatialTransformer(\n",
       "            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): CrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): CrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (8): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (1): SpatialTransformer(\n",
       "            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): CrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): CrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (9): TimestepEmbedSequential(\n",
       "          (0): Downsample(\n",
       "            (op): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (10): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "        )\n",
       "        (11): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (middle_block): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "      )\n",
       "      (output_blocks): ModuleList(\n",
       "        (0): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Upsample(\n",
       "            (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (3): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatialTransformer(\n",
       "            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): CrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): CrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (4): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatialTransformer(\n",
       "            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): CrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): CrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (5): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatialTransformer(\n",
       "            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): CrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): CrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Upsample(\n",
       "            (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (6): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatialTransformer(\n",
       "            (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): CrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): CrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (7): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatialTransformer(\n",
       "            (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): CrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): CrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (8): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatialTransformer(\n",
       "            (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): CrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): CrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Upsample(\n",
       "            (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (9): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatialTransformer(\n",
       "            (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "            (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): CrossAttention(\n",
       "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): CrossAttention(\n",
       "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (10): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatialTransformer(\n",
       "            (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "            (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): CrossAttention(\n",
       "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): CrossAttention(\n",
       "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (11): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatialTransformer(\n",
       "            (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "            (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): CrossAttention(\n",
       "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): CrossAttention(\n",
       "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=320, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (out): Sequential(\n",
       "        (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (first_stage_model): AutoencoderKL(\n",
       "    (encoder): Encoder(\n",
       "      (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (down): ModuleList(\n",
       "        (0): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (downsample): Downsample(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "        (1): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nin_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (downsample): Downsample(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "        (2): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nin_shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (downsample): Downsample(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "        (3): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "        )\n",
       "      )\n",
       "      (mid): Module(\n",
       "        (block_1): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (attn_1): AttnBlock(\n",
       "          (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (block_2): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (norm_out): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "      (conv_out): Conv2d(512, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (decoder): Decoder(\n",
       "      (conv_in): Conv2d(4, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (mid): Module(\n",
       "        (block_1): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (attn_1): AttnBlock(\n",
       "          (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (block_2): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (up): ModuleList(\n",
       "        (0): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nin_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (2): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "        )\n",
       "        (1): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nin_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (2): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (upsample): Upsample(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (2): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (upsample): Upsample(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (3): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (2): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (upsample): Upsample(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm_out): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "      (conv_out): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (loss): Identity()\n",
       "    (quant_conv): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (post_quant_conv): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (cond_stage_model): BERTEmbedder(\n",
       "    (tknz_fn): BERTTokenizer()\n",
       "    (transformer): TransformerWrapper(\n",
       "      (token_emb): Embedding(30522, 1280)\n",
       "      (pos_emb): AbsolutePositionalEmbedding(\n",
       "        (emb): Embedding(77, 1280)\n",
       "      )\n",
       "      (emb_dropout): Dropout(p=0.0, inplace=False)\n",
       "      (project_emb): Identity()\n",
       "      (attn_layers): Encoder(\n",
       "        (layers): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=1280, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=1280, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (3): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (4): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=1280, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (5): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (6): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=1280, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (7): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (8): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=1280, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (9): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (10): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=1280, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (11): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (12): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=1280, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (13): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (14): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=1280, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (15): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (16): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=1280, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (17): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (18): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=1280, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (19): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (20): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=1280, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (21): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (22): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=1280, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (23): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (24): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=1280, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (25): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (26): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=1280, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (27): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (28): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=1280, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (29): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (30): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=1280, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (31): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (32): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=1280, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (33): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (34): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=1280, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (35): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (36): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=1280, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (37): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (38): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=1280, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (39): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (40): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=1280, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (41): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (42): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=1280, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (43): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (44): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=1280, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (45): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (46): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=1280, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (47): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (48): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=1280, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (49): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (50): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=1280, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (51): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (52): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=1280, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (53): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (54): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=1280, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (55): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (56): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=1280, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (57): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (58): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=1280, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (59): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (60): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=1280, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (61): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (62): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=1280, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (63): ModuleList(\n",
       "            (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (to_logits): Linear(in_features=1280, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1edc94a-f906-42dd-af18-a380d3df1d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "uc = model.get_learned_conditioning(opt.n_samples * [\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6c6abd8-0675-4327-9bd6-8ca1edcacd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for opt.n_iter = 1\n",
    "c = model.get_learned_conditioning(opt.n_samples * [prompt])\n",
    "shape = [4, opt.H//8, opt.W//8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1440039-27ce-4790-be90-ba0490443d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 77, 1280])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ac74fa7-dcb5-4bc7-8911-60297066764b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (1, 4, 48, 128), eta 1.0\n",
      "Running DDIM Sampling with 200 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ...\n"
     ]
    }
   ],
   "source": [
    "samples_ddim, _ = sampler.sample(S=opt.ddim_steps,\n",
    "     conditioning=c,\n",
    "     batch_size=opt.n_samples,\n",
    "     shape=shape,\n",
    "     verbose=False,\n",
    "     unconditional_guidance_scale=opt.scale,\n",
    "     unconditional_conditioning=uc,\n",
    "     eta=opt.ddim_eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac5445e3-decb-439d-8553-8a012b3fc008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 48, 128])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_ddim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f482eb33-5ead-46f5-963b-539702b8c802",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_samples_ddim = model.decode_first_stage(samples_ddim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89b2094-c036-4cb9-8ad3-df488d975fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_samples_ddim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188bf616-a284-4f3b-9897-97d98a28cf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_samples_ddim = torch.clamp((x_samples_ddim+1.0)/2.0, min=0.0, max=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b021a5b-31f4-4adc-97be-15adee132e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_sample in x_samples_ddim:\n",
    "    x_sample = 255. * rearrange(x_sample.cpu().numpy(), 'c h w -> h w c')\n",
    "    Image.fromarray(x_sample.astype(np.uint8)).save(os.path.join(sample_path, f\"{base_count:04}.png\"))\n",
    "    base_count += 1\n",
    "    \n",
    "all_samples.append(x_samples_ddim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadb7892-fde6-46ab-94d0-11266c098e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additionally, save as grid\n",
    "grid = torch.stack(all_samples, 0)\n",
    "grid = rearrange(grid, 'n b c h w -> (n b) c h w')\n",
    "grid = make_grid(grid, nrow=opt.n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5c9450-8ef1-4a1f-8ab0-b86a05685c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to image\n",
    "grid = 255. * rearrange(grid, 'c h w -> h w c').cpu().numpy()\n",
    "Image.fromarray(grid.astype(np.uint8)).save(os.path.join(outpath, f'{prompt.replace(\" \", \"-\")}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19588d8-10b1-418f-b0e9-6499b1131a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f59e4e-d8b6-434d-a042-ef16b88de882",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d07f4e48-ae0d-49a7-8e67-d07113416bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling\n",
    "shape = [4, opt.H//8, opt.W//8]\n",
    "# C, H, W = shape\n",
    "# size = (1, C, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "618f6f92-33f5-4273-9ece-4403dd47da64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected timesteps for ddim sampler: [  1   6  11  16  21  26  31  36  41  46  51  56  61  66  71  76  81  86\n",
      "  91  96 101 106 111 116 121 126 131 136 141 146 151 156 161 166 171 176\n",
      " 181 186 191 196 201 206 211 216 221 226 231 236 241 246 251 256 261 266\n",
      " 271 276 281 286 291 296 301 306 311 316 321 326 331 336 341 346 351 356\n",
      " 361 366 371 376 381 386 391 396 401 406 411 416 421 426 431 436 441 446\n",
      " 451 456 461 466 471 476 481 486 491 496 501 506 511 516 521 526 531 536\n",
      " 541 546 551 556 561 566 571 576 581 586 591 596 601 606 611 616 621 626\n",
      " 631 636 641 646 651 656 661 666 671 676 681 686 691 696 701 706 711 716\n",
      " 721 726 731 736 741 746 751 756 761 766 771 776 781 786 791 796 801 806\n",
      " 811 816 821 826 831 836 841 846 851 856 861 866 871 876 881 886 891 896\n",
      " 901 906 911 916 921 926 931 936 941 946 951 956 961 966 971 976 981 986\n",
      " 991 996]\n",
      "Selected alphas for ddim sampler: a_t: tensor([0.9983, 0.9940, 0.9895, 0.9850, 0.9804, 0.9757, 0.9708, 0.9659, 0.9609,\n",
      "        0.9557, 0.9505, 0.9452, 0.9398, 0.9343, 0.9287, 0.9229, 0.9171, 0.9112,\n",
      "        0.9052, 0.8992, 0.8930, 0.8867, 0.8804, 0.8739, 0.8674, 0.8607, 0.8540,\n",
      "        0.8473, 0.8404, 0.8334, 0.8264, 0.8193, 0.8121, 0.8049, 0.7975, 0.7901,\n",
      "        0.7827, 0.7751, 0.7675, 0.7599, 0.7521, 0.7444, 0.7365, 0.7286, 0.7207,\n",
      "        0.7127, 0.7047, 0.6966, 0.6885, 0.6803, 0.6722, 0.6639, 0.6557, 0.6474,\n",
      "        0.6391, 0.6307, 0.6224, 0.6140, 0.6056, 0.5972, 0.5888, 0.5804, 0.5720,\n",
      "        0.5636, 0.5551, 0.5467, 0.5383, 0.5299, 0.5215, 0.5132, 0.5048, 0.4965,\n",
      "        0.4882, 0.4799, 0.4716, 0.4634, 0.4552, 0.4471, 0.4390, 0.4309, 0.4229,\n",
      "        0.4149, 0.4070, 0.3991, 0.3913, 0.3835, 0.3758, 0.3681, 0.3605, 0.3530,\n",
      "        0.3456, 0.3382, 0.3308, 0.3236, 0.3164, 0.3093, 0.3023, 0.2954, 0.2885,\n",
      "        0.2817, 0.2750, 0.2684, 0.2618, 0.2554, 0.2490, 0.2428, 0.2366, 0.2305,\n",
      "        0.2245, 0.2186, 0.2128, 0.2071, 0.2014, 0.1959, 0.1905, 0.1851, 0.1799,\n",
      "        0.1747, 0.1696, 0.1647, 0.1598, 0.1550, 0.1504, 0.1458, 0.1413, 0.1369,\n",
      "        0.1326, 0.1284, 0.1243, 0.1203, 0.1163, 0.1125, 0.1087, 0.1051, 0.1015,\n",
      "        0.0980, 0.0946, 0.0913, 0.0881, 0.0850, 0.0819, 0.0789, 0.0761, 0.0732,\n",
      "        0.0705, 0.0679, 0.0653, 0.0628, 0.0604, 0.0580, 0.0557, 0.0535, 0.0514,\n",
      "        0.0493, 0.0473, 0.0453, 0.0435, 0.0416, 0.0399, 0.0382, 0.0365, 0.0350,\n",
      "        0.0334, 0.0320, 0.0305, 0.0292, 0.0279, 0.0266, 0.0254, 0.0242, 0.0231,\n",
      "        0.0220, 0.0210, 0.0200, 0.0190, 0.0181, 0.0172, 0.0163, 0.0155, 0.0147,\n",
      "        0.0140, 0.0133, 0.0126, 0.0120, 0.0113, 0.0107, 0.0102, 0.0096, 0.0091,\n",
      "        0.0086, 0.0082, 0.0077, 0.0073, 0.0069, 0.0065, 0.0061, 0.0058, 0.0054,\n",
      "        0.0051, 0.0048]); a_(t-1): [0.99914998 0.99829602 0.99396652 0.98953754 0.98500896 0.98038077\n",
      " 0.97565293 0.97082555 0.96589875 0.96087277 0.95574784 0.95052433\n",
      " 0.94520253 0.93978298 0.93426609 0.92865258 0.92294294 0.91713792\n",
      " 0.91123831 0.90524495 0.89915872 0.89298052 0.88671148 0.88035256\n",
      " 0.873905   0.86737001 0.86074883 0.85404283 0.84725332 0.84038192\n",
      " 0.83342999 0.82639927 0.81929123 0.81210774 0.80485046 0.79752123\n",
      " 0.79012191 0.78265446 0.77512079 0.76752299 0.7598632  0.75214338\n",
      " 0.74436587 0.73653287 0.72864658 0.72070938 0.71272361 0.70469165\n",
      " 0.69661599 0.68849909 0.68034339 0.67215145 0.66392595 0.65566933\n",
      " 0.64738435 0.63907355 0.63073969 0.62238538 0.61401343 0.60562652\n",
      " 0.59722733 0.58881873 0.58040333 0.57198399 0.56356353 0.55514455\n",
      " 0.54672998 0.53832245 0.52992481 0.52153981 0.51317018 0.50481856\n",
      " 0.49648774 0.4881804  0.4798992  0.47164679 0.46342579 0.45523876\n",
      " 0.44708833 0.43897697 0.43090722 0.42288151 0.4149023  0.4069719\n",
      " 0.39909273 0.39126703 0.38349706 0.37578499 0.36813304 0.36054322\n",
      " 0.35301763 0.34555823 0.33816692 0.33084565 0.32359615 0.3164202\n",
      " 0.3093195  0.30229566 0.29535022 0.28848472 0.28170055 0.27499905\n",
      " 0.26838157 0.26184931 0.2554034  0.24904492 0.24277493 0.23659433\n",
      " 0.23050404 0.22450483 0.21859743 0.21278252 0.20706069 0.20143245\n",
      " 0.19589828 0.19045855 0.18511358 0.1798636  0.17470883 0.16964935\n",
      " 0.16468522 0.15981644 0.15504292 0.1503645  0.14578101 0.14129217\n",
      " 0.13689767 0.1325971  0.12839006 0.12427604 0.1202545  0.11632485\n",
      " 0.11248643 0.10873855 0.10508047 0.1015114  0.0980305  0.09463691\n",
      " 0.09132971 0.08810794 0.08497062 0.08191671 0.07894517 0.07605491\n",
      " 0.0732448  0.0705137  0.06786042 0.0652838  0.06278259 0.06035557\n",
      " 0.05800147 0.05571903 0.05350694 0.05136392 0.04928865 0.04727979\n",
      " 0.04533602 0.043456   0.0416384  0.03988184 0.038185   0.03654652\n",
      " 0.03496506 0.03343925 0.03196777 0.03054927 0.02918243 0.02786591\n",
      " 0.02659841 0.02537862 0.02420524 0.02307699 0.0219926  0.02095082\n",
      " 0.0199504  0.01899013 0.01806878 0.01718517 0.01633812 0.01552648\n",
      " 0.01474911 0.0140049  0.01329274 0.01261155 0.01196029 0.01133791\n",
      " 0.01074341 0.01017578 0.00963406 0.00911731 0.00862459 0.008155\n",
      " 0.00770767 0.00728173 0.00687634 0.0064907  0.00612401 0.0057755\n",
      " 0.00544443 0.00513007]\n",
      "For the chosen value of eta, which is 1.0, this results in the following sigma_t schedule for ddim sampler tensor([0.0206, 0.0350, 0.0507, 0.0565, 0.0599, 0.0623, 0.0643, 0.0659, 0.0673,\n",
      "        0.0687, 0.0699, 0.0711, 0.0722, 0.0733, 0.0744, 0.0755, 0.0765, 0.0775,\n",
      "        0.0785, 0.0795, 0.0805, 0.0814, 0.0824, 0.0834, 0.0843, 0.0853, 0.0862,\n",
      "        0.0872, 0.0881, 0.0890, 0.0900, 0.0909, 0.0918, 0.0928, 0.0937, 0.0946,\n",
      "        0.0955, 0.0965, 0.0974, 0.0983, 0.0992, 0.1001, 0.1010, 0.1020, 0.1029,\n",
      "        0.1038, 0.1047, 0.1056, 0.1065, 0.1074, 0.1084, 0.1093, 0.1102, 0.1111,\n",
      "        0.1120, 0.1129, 0.1138, 0.1147, 0.1156, 0.1165, 0.1174, 0.1183, 0.1193,\n",
      "        0.1202, 0.1211, 0.1220, 0.1229, 0.1238, 0.1247, 0.1256, 0.1265, 0.1274,\n",
      "        0.1283, 0.1292, 0.1301, 0.1310, 0.1319, 0.1328, 0.1337, 0.1346, 0.1355,\n",
      "        0.1364, 0.1373, 0.1382, 0.1391, 0.1400, 0.1409, 0.1418, 0.1427, 0.1436,\n",
      "        0.1445, 0.1454, 0.1463, 0.1472, 0.1481, 0.1490, 0.1499, 0.1508, 0.1517,\n",
      "        0.1526, 0.1535, 0.1544, 0.1553, 0.1562, 0.1571, 0.1580, 0.1589, 0.1598,\n",
      "        0.1607, 0.1616, 0.1625, 0.1634, 0.1643, 0.1652, 0.1661, 0.1670, 0.1679,\n",
      "        0.1688, 0.1697, 0.1705, 0.1714, 0.1723, 0.1732, 0.1741, 0.1750, 0.1759,\n",
      "        0.1768, 0.1777, 0.1786, 0.1795, 0.1804, 0.1813, 0.1821, 0.1830, 0.1839,\n",
      "        0.1848, 0.1857, 0.1866, 0.1875, 0.1884, 0.1893, 0.1902, 0.1910, 0.1919,\n",
      "        0.1928, 0.1937, 0.1946, 0.1955, 0.1964, 0.1972, 0.1981, 0.1990, 0.1999,\n",
      "        0.2008, 0.2017, 0.2026, 0.2034, 0.2043, 0.2052, 0.2061, 0.2070, 0.2079,\n",
      "        0.2087, 0.2096, 0.2105, 0.2114, 0.2123, 0.2131, 0.2140, 0.2149, 0.2158,\n",
      "        0.2167, 0.2175, 0.2184, 0.2193, 0.2202, 0.2210, 0.2219, 0.2228, 0.2237,\n",
      "        0.2245, 0.2254, 0.2263, 0.2272, 0.2280, 0.2289, 0.2298, 0.2307, 0.2315,\n",
      "        0.2324, 0.2333, 0.2342, 0.2350, 0.2359, 0.2368, 0.2376, 0.2385, 0.2394,\n",
      "        0.2403, 0.2411], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "sampler.make_schedule(ddim_num_steps=opt.ddim_steps, ddim_eta=opt.ddim_eta, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7ee13ca-f4dd-46d3-a1e2-a6767769a9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "C, H, W = shape\n",
    "size = (1, C, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f610089f-bd1c-44af-863a-64107b9d82a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 48, 128)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59141817-6355-4fe7-ac46-a8de10f7f665",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "184c0430-c838-4ff2-a8f2-6024b91c6a99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# samples, intermediates = sampler.ddim_sampling(c, size,\n",
    "#             unconditional_guidance_scale=opt.scale,\n",
    "#             unconditional_conditioning=uc,\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f5328f4-6038-468b-b06c-2c57f2d6242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = c\n",
    "x_T = None\n",
    "timesteps = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "42fdc3db-40f0-4cfe-9210-4cf1cb3c1c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = None\n",
    "unconditional_guidance_scale = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9f5f2d47-a61a-4dd2-a65f-04b5c8510515",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = sampler.model.betas.device\n",
    "b = 1\n",
    "if x_T is None:\n",
    "    img = torch.randn(shape, device=device)\n",
    "else:\n",
    "    img = x_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "31f7a430-3481-4489-966a-e40aa80027a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddim_use_original_steps = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6fd54f99-2e95-4475-96ea-8c1830d72426",
   "metadata": {},
   "outputs": [],
   "source": [
    "if timesteps is None:\n",
    "    timesteps = sampler.ddpm_num_timesteps if ddim_use_original_steps else sampler.ddim_timesteps\n",
    "elif timesteps is not None and not ddim_use_original_steps:\n",
    "    subset_end = int(min(timesteps / sampler.ddim_timesteps.shape[0], 1) * sampler.ddim_timesteps.shape[0]) - 1\n",
    "    timesteps = sampler.ddim_timesteps[:subset_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8cd5af77-5a0f-4fbb-b2e0-06341407a677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DDIM Sampling with 200 timesteps\n"
     ]
    }
   ],
   "source": [
    "intermediates = {'x_inter': [img], 'pred_x0': [img]}\n",
    "time_range = reversed(range(0,timesteps)) if ddim_use_original_steps else np.flip(timesteps)\n",
    "total_steps = timesteps if ddim_use_original_steps else timesteps.shape[0]\n",
    "print(f\"Running DDIM Sampling with {total_steps} timesteps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "82dd334e-46ff-4929-92c1-6beef3f2e35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    }
   ],
   "source": [
    "iterator = tqdm(time_range, desc='DDIM Sampler', total=total_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "88f36e5b-7399-470d-b572-967cd3def6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ...\n"
     ]
    }
   ],
   "source": [
    "i, step = next(iter( enumerate(iterator)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f6e6512f-7968-42ce-a340-eaf3eae47213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 996)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i, step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ecb6c65-996c-46fd-b0d9-7d73c3b51ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = total_steps - i - 1\n",
    "ts = torch.full((b,), step, device=device, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e06506bb-b91a-4451-a45c-80ab8f410093",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mask is not None:\n",
    "    assert x0 is not None\n",
    "    img_orig = self.model.q_sample(x0, ts)  # TODO: deterministic forward pass?\n",
    "    img = img_orig * mask + (1. - mask) * img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ae0551a6-2ed4-4569-b28f-0231e99e7704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    }
   ],
   "source": [
    "# outs = sampler.p_sample_ddim(img, cond, ts, index=index, use_original_steps=ddim_use_original_steps,\n",
    "#           unconditional_guidance_scale=opt.scale,\n",
    "#           unconditional_conditioning=uc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0c7460d4-9666-4a9c-80b1-8d8272c559d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = img\n",
    "t = ts\n",
    "c = cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "833b0d72-abf3-4712-afdf-c22beda75193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in, t_in, c_in torch.Size([2, 4, 48, 128]) torch.Size([2]) torch.Size([2, 77, 1280])\n"
     ]
    }
   ],
   "source": [
    "x_in = torch.cat([x] * 2)\n",
    "t_in = torch.cat([t] * 2)\n",
    "c_in = torch.cat([uc, c])\n",
    "print(\"x_in, t_in, c_in\", x_in.shape, t_in.shape, c_in.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "37f51f73-1a6f-4a01-8c30-376c365e34d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_noisy, t, cond = x_in, t_in, c_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "572c9ce7-6e81-411f-ab7f-6e0f913065c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(cond, dict):\n",
    "    # hybrid case, cond is exptected to be a dict\n",
    "    pass\n",
    "else:\n",
    "    if not isinstance(cond, list):\n",
    "        cond = [cond]\n",
    "    key = 'c_concat' if model.model.conditioning_key == 'concat' else 'c_crossattn'\n",
    "    cond = {key: cond}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "61fa5b40-4def-450a-99f1-aadba05cb0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_recon = model.model(x_noisy, t, **cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9b2f7260-468f-4777-b74e-06cc3776034e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "e_t_uncond, e_t = sampler.model.apply_model(x_in, t_in, c_in).chunk(2)\n",
    "e_t = e_t_uncond + unconditional_guidance_scale * (e_t - e_t_uncond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "51adedc0-3512-4671-9dcd-1b26926e2d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 48, 128])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "65f32535-475f-4e8b-98e9-cb626aa83396",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_original_steps = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "df6d9942-be46-4f24-9b25-025297dce202",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = sampler.model.alphas_cumprod if use_original_steps else sampler.ddim_alphas\n",
    "alphas_prev = sampler.model.alphas_cumprod_prev if use_original_steps else sampler.ddim_alphas_prev\n",
    "sqrt_one_minus_alphas = sampler.model.sqrt_one_minus_alphas_cumprod if use_original_steps else sampler.ddim_sqrt_one_minus_alphas\n",
    "sigmas = sampler.model.ddim_sigmas_for_original_num_steps if use_original_steps else sampler.ddim_sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1de20579-e264-49d5-9048-77a04cc8f252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select parameters corresponding to the currently considered timestep\n",
    "a_t = torch.full((b, 1, 1, 1), alphas[index], device=device)\n",
    "a_prev = torch.full((b, 1, 1, 1), alphas_prev[index], device=device)\n",
    "sigma_t = torch.full((b, 1, 1, 1), sigmas[index], device=device)\n",
    "sqrt_one_minus_at = torch.full((b, 1, 1, 1), sqrt_one_minus_alphas[index],device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c028db98-86bf-4db3-9945-ea6e43b91e06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vrkit",
   "language": "python",
   "name": "vrkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
